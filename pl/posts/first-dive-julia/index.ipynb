{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm currently sitting in at a tutorial on the basics of Julia and parallel processing therein by [Bogumił Kamiński](http://bogumilkaminski.pl/dydaktyka/). This is actually my first dive into Julia, so I thought I would write it down on-the-go here!\n",
    "\n",
    "<!-- TEASER_END -->\n",
    "\n",
    "Let's jump right into it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000×10000 Array{Float64,2}:\n",
       " -0.324424   -0.565317    0.74943    …  -0.518865    -0.0841272   0.935276 \n",
       "  2.7421      0.127783   -0.406756       1.69075      1.58605     0.302112 \n",
       "  2.00937    -0.36474    -1.6031         2.46846     -0.319774   -0.362626 \n",
       "  1.0957     -0.328512    0.0765665      0.551588    -0.63376    -0.642072 \n",
       " -1.5761      0.0990041   0.649661       0.123745     1.53702     0.748066 \n",
       "  0.0294794   0.841421    0.935812   …  -0.124979    -0.0319694  -0.308331 \n",
       "  2.4428     -0.0981946   2.16323       -1.74004     -0.838027   -0.562755 \n",
       " -0.362584   -0.342403    1.11269       -1.99102      2.13044     1.05996  \n",
       " -0.85741     0.224304    0.89256       -0.357627    -0.25959     0.271416 \n",
       "  1.02282    -0.470008    1.75296        1.34871     -0.16343     0.194525 \n",
       " -0.357741    0.252059   -1.02996    …  -0.125655    -1.20237     0.0220102\n",
       "  0.793983    0.334861   -0.628246      -0.768169     1.08063    -0.870663 \n",
       " -0.111529   -0.557087    0.714131      -0.0785655    0.577348   -0.659775 \n",
       "  ⋮                                  ⋱                                     \n",
       "  0.454754    0.905449   -1.04019       -2.14169     -0.830821    0.363394 \n",
       "  0.165472   -0.099097    1.58675       -0.314269    -0.500922   -2.24592  \n",
       " -0.74685     0.854795   -0.606661   …   0.390252    -1.45657     1.22648  \n",
       " -0.0369208  -0.139647    1.26695       -0.00442996  -2.24374     0.348733 \n",
       "  0.620604   -0.835141   -1.59741       -0.026424    -0.491713    0.705191 \n",
       " -2.49094     0.471711    0.677353       0.51443     -0.234433    1.61501  \n",
       " -0.600199    0.907787   -0.0977633      1.39034     -1.20908     1.06054  \n",
       " -1.26894     0.718772    0.334036   …   0.994015    -1.28285    -2.15419  \n",
       " -0.411544   -0.0794345   1.58904        1.14895      0.0363      2.14895  \n",
       " -0.437881   -0.451166   -0.0647529     -0.276704     0.392206   -0.128466 \n",
       "  0.86126     0.774654    0.429458      -2.03196     -0.371577    0.547281 \n",
       " -1.07246     0.421693   -0.244775      -0.479385    -0.858759   -0.300843 "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = randn(10000, 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, that did what you'd expect. There's apparently a help statement that works inversely from what you'd expect from IPython:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: \u001b[0m\u001b[1mr\u001b[22m\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1md\u001b[22m\u001b[0m\u001b[1mn\u001b[22m \u001b[0m\u001b[1mr\u001b[22m\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1md\u001b[22m t\u001b[0m\u001b[1mr\u001b[22m\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1mn\u001b[22msco\u001b[0m\u001b[1md\u001b[22me mac\u001b[0m\u001b[1mr\u001b[22moexp\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1md\u001b[22m @mac\u001b[0m\u001b[1mr\u001b[22moexp\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1md\u001b[22m1 @mac\u001b[0m\u001b[1mr\u001b[22moexp\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1md\u001b[22m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "randn([rng=GLOBAL_RNG], [T=Float64], [dims...])\n",
       "\\end{verbatim}\n",
       "Generate a normally-distributed random number of type \\texttt{T} with mean 0 and standard deviation 1. Optionally generate an array of normally-distributed random numbers. The \\texttt{Base} module currently provides an implementation for the types \\href{@ref}{\\texttt{Float16}}, \\href{@ref}{\\texttt{Float32}}, and \\href{@ref}{\\texttt{Float64}} (the default), and their \\href{@ref}{\\texttt{Complex}} counterparts. When the type argument is complex, the values are drawn from the circularly symmetric complex normal distribution.\n",
       "\n",
       "\\section{Examples}\n",
       "\\begin{verbatim}\n",
       "julia> rng = MersenneTwister(1234);\n",
       "\n",
       "julia> randn(rng, ComplexF64)\n",
       "0.6133070881429037 - 0.6376291670853887im\n",
       "\n",
       "julia> randn(rng, ComplexF32, (2, 3))\n",
       "2×3 Array{Complex{Float32},2}:\n",
       " -0.349649-0.638457im  0.376756-0.192146im  -0.396334-0.0136413im\n",
       "  0.611224+1.56403im   0.355204-0.365563im  0.0905552+1.31012im\n",
       "\\end{verbatim}\n"
      ],
      "text/markdown": [
       "```\n",
       "randn([rng=GLOBAL_RNG], [T=Float64], [dims...])\n",
       "```\n",
       "\n",
       "Generate a normally-distributed random number of type `T` with mean 0 and standard deviation 1. Optionally generate an array of normally-distributed random numbers. The `Base` module currently provides an implementation for the types [`Float16`](@ref), [`Float32`](@ref), and [`Float64`](@ref) (the default), and their [`Complex`](@ref) counterparts. When the type argument is complex, the values are drawn from the circularly symmetric complex normal distribution.\n",
       "\n",
       "# Examples\n",
       "\n",
       "```jldoctest\n",
       "julia> rng = MersenneTwister(1234);\n",
       "\n",
       "julia> randn(rng, ComplexF64)\n",
       "0.6133070881429037 - 0.6376291670853887im\n",
       "\n",
       "julia> randn(rng, ComplexF32, (2, 3))\n",
       "2×3 Array{Complex{Float32},2}:\n",
       " -0.349649-0.638457im  0.376756-0.192146im  -0.396334-0.0136413im\n",
       "  0.611224+1.56403im   0.355204-0.365563im  0.0905552+1.31012im\n",
       "```\n"
      ],
      "text/plain": [
       "\u001b[36m  randn([rng=GLOBAL_RNG], [T=Float64], [dims...])\u001b[39m\n",
       "\n",
       "  Generate a normally-distributed random number of type \u001b[36mT\u001b[39m with mean 0 and\n",
       "  standard deviation 1. Optionally generate an array of normally-distributed\n",
       "  random numbers. The \u001b[36mBase\u001b[39m module currently provides an implementation for the\n",
       "  types \u001b[36mFloat16\u001b[39m, \u001b[36mFloat32\u001b[39m, and \u001b[36mFloat64\u001b[39m (the default), and their \u001b[36mComplex\u001b[39m\n",
       "  counterparts. When the type argument is complex, the values are drawn from\n",
       "  the circularly symmetric complex normal distribution.\n",
       "\n",
       "\u001b[1m  Examples\u001b[22m\n",
       "\u001b[1m  ≡≡≡≡≡≡≡≡≡≡\u001b[22m\n",
       "\n",
       "\u001b[36m  julia> rng = MersenneTwister(1234);\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> randn(rng, ComplexF64)\u001b[39m\n",
       "\u001b[36m  0.6133070881429037 - 0.6376291670853887im\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> randn(rng, ComplexF32, (2, 3))\u001b[39m\n",
       "\u001b[36m  2×3 Array{Complex{Float32},2}:\u001b[39m\n",
       "\u001b[36m   -0.349649-0.638457im  0.376756-0.192146im  -0.396334-0.0136413im\u001b[39m\n",
       "\u001b[36m    0.611224+1.56403im   0.355204-0.365563im  0.0905552+1.31012im\u001b[39m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?randn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about global help?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: ⊻ ⊋ ⊊ ⊉ ⊈ ⊇ ⊆ ≥ ≤ ≢ ≡ ≠ ≉ ≈ ∪ ∩ ∛ √ ∘ ∌ ∋ ∉ ∈ ℯ π ÷ ~ | ^ \\ > < : / - +\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\textbf{Welcome to Julia 1.1.0.} The full manual is available at\n",
       "\n",
       "\\begin{verbatim}\n",
       "https://docs.julialang.org/\n",
       "\\end{verbatim}\n",
       "as well as many great tutorials and learning resources:\n",
       "\n",
       "\\begin{verbatim}\n",
       "https://julialang.org/learning/\n",
       "\\end{verbatim}\n",
       "For help on a specific function or macro, type \\texttt{?} followed by its name, e.g. \\texttt{?cos}, or \\texttt{?@time}, and press enter. Type \\texttt{;} to enter shell mode, \\texttt{]} to enter package mode.\n",
       "\n"
      ],
      "text/markdown": [
       "**Welcome to Julia 1.1.0.** The full manual is available at\n",
       "\n",
       "```\n",
       "https://docs.julialang.org/\n",
       "```\n",
       "\n",
       "as well as many great tutorials and learning resources:\n",
       "\n",
       "```\n",
       "https://julialang.org/learning/\n",
       "```\n",
       "\n",
       "For help on a specific function or macro, type `?` followed by its name, e.g. `?cos`, or `?@time`, and press enter. Type `;` to enter shell mode, `]` to enter package mode.\n"
      ],
      "text/plain": [
       "  \u001b[1mWelcome to Julia 1.1.0.\u001b[22m The full manual is available at\n",
       "\n",
       "\u001b[36m  https://docs.julialang.org/\u001b[39m\n",
       "\n",
       "  as well as many great tutorials and learning resources:\n",
       "\n",
       "\u001b[36m  https://julialang.org/learning/\u001b[39m\n",
       "\n",
       "  For help on a specific function or macro, type \u001b[36m?\u001b[39m followed by its name, e.g.\n",
       "  \u001b[36m?cos\u001b[39m, or \u001b[36m?@time\u001b[39m, and press enter. Type \u001b[36m;\u001b[39m to enter shell mode, \u001b[36m]\u001b[39m to enter\n",
       "  package mode."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist.zip\n",
      "Tutorial1.ipynb\n"
     ]
    }
   ],
   "source": [
    ";ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `@time` to benchmark this `randn` command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.813875 seconds (6 allocations: 762.940 MiB, 1.56% gc time)\n"
     ]
    }
   ],
   "source": [
    "@time randn(10000, 10000);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison:\n",
    "\n",
    "```ipython\n",
    "In [3]: %timeit np.random.normal(size=(10000, 10000))             \n",
    "3.8 s ± 25.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "```\n",
    "\n",
    "And the presenter's R attempt took 5.81 using `system.time`. Wew, this is pretty fast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start with, we're analyzing [a function found on StackOverflow](https://stackoverflow.com/questions/55147566/julia-parallel-computing-for-loop) that sums over the lower triangular part of a matrix (apparently, the code is pretty bad):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-7802.649783031088"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function upsum(M); n = size(M)[1]; sum = 0\n",
    "    for i = 1:n-1\n",
    "        for j = i+1:n\n",
    "            sum = sum + M[i,j]\n",
    "        end\n",
    "    end\n",
    "    return sum\n",
    "end\n",
    "\n",
    "upsum(R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "The analogue of IPython's \\texttt{\\%time statement} (also \\texttt{\\%timeit}) in Julia is \\texttt{@time statement}.  The analogue of \\texttt{\\%\\%time ...code...} is\n",
       "\n",
       "\\begin{verbatim}\n",
       "@time begin\n",
       "    ...code...\n",
       "end\n",
       "\\end{verbatim}\n",
       "Note, however, that you should put all performance-critical code into a function, avoiding global variables, before doing performance measurements in Julia; see the \\href{http://docs.julialang.org/en/latest/manual/performance-tips/}{performance tips in the Julia manual}.\n",
       "\n",
       "The \\texttt{@time} macro prints the timing results, and returns the value of evaluating the expression.  To instead return the time (in seconds), use \\texttt{@elapsed statement}.\n",
       "\n",
       "For more extensive benchmarking tools, including the ability to collect statistics from multiple runs, see the \\href{https://github.com/JuliaCI/BenchmarkTools.jl}{BenchmarkTools package}.\n",
       "\n"
      ],
      "text/markdown": [
       "The analogue of IPython's `%time statement` (also `%timeit`) in Julia is `@time statement`.  The analogue of `%%time ...code...` is\n",
       "\n",
       "```\n",
       "@time begin\n",
       "    ...code...\n",
       "end\n",
       "```\n",
       "\n",
       "Note, however, that you should put all performance-critical code into a function, avoiding global variables, before doing performance measurements in Julia; see the [performance tips in the Julia manual](http://docs.julialang.org/en/latest/manual/performance-tips/).\n",
       "\n",
       "The `@time` macro prints the timing results, and returns the value of evaluating the expression.  To instead return the time (in seconds), use `@elapsed statement`.\n",
       "\n",
       "For more extensive benchmarking tools, including the ability to collect statistics from multiple runs, see the [BenchmarkTools package](https://github.com/JuliaCI/BenchmarkTools.jl).\n"
      ],
      "text/plain": [
       "  The analogue of IPython's \u001b[36m%time statement\u001b[39m (also \u001b[36m%timeit\u001b[39m) in Julia is \u001b[36m@time\n",
       "  statement\u001b[39m. The analogue of \u001b[36m%%time ...code...\u001b[39m is\n",
       "\n",
       "\u001b[36m  @time begin\u001b[39m\n",
       "\u001b[36m      ...code...\u001b[39m\n",
       "\u001b[36m  end\u001b[39m\n",
       "\n",
       "  Note, however, that you should put all performance-critical code into a\n",
       "  function, avoiding global variables, before doing performance measurements\n",
       "  in Julia; see the performance tips in the Julia manual\n",
       "  (http://docs.julialang.org/en/latest/manual/performance-tips/).\n",
       "\n",
       "  The \u001b[36m@time\u001b[39m macro prints the timing results, and returns the value of\n",
       "  evaluating the expression. To instead return the time (in seconds), use\n",
       "  \u001b[36m@elapsed statement\u001b[39m.\n",
       "\n",
       "  For more extensive benchmarking tools, including the ability to collect\n",
       "  statistics from multiple runs, see the BenchmarkTools package\n",
       "  (https://github.com/JuliaCI/BenchmarkTools.jl)."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%timeit upsum(R);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... All right, I'm starting to like this cheeky little language. Trying again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.464638 seconds (5 allocations: 176 bytes)\n"
     ]
    }
   ],
   "source": [
    "@time upsum(R);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare that with Python:\n",
    "\n",
    "```ipython\n",
    "In [8]: %timeit np.sum(np.tril(R))                                \n",
    "245 ms ± 45.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "```\n",
    "\n",
    "Well, that was faster, but we can improve the Julia code. Let's first look at the inbuilt `sum` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sum (generic function with 13 methods)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.090729 seconds (89.03 k allocations: 4.748 MiB, 10.32% gc time)\n"
     ]
    }
   ],
   "source": [
    "@time sum(R);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.100551 seconds (5 allocations: 176 bytes)\n"
     ]
    }
   ],
   "source": [
    "@time sum(R);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now this is badass. Julia is **dynamically compiled** - it's as if Numba came out of Python and became its own language. Apparently there are ways of avoiding the first-call overhead, but this is somehow more advanced.\n",
    "\n",
    "Note that all compiled-function cache is cleared on Julia restarts!\n",
    "\n",
    "To compare with Python:\n",
    "\n",
    "```ipython\n",
    "In [9]: %timeit np.sum(R)                                         \n",
    "53 ms ± 3.67 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
    "```\n",
    "\n",
    "Not too shabby for the ol' snake!\n",
    "\n",
    "Let's try to improve the function, though:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-7802.6497830305125"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function uppersum(M)\n",
    "    n = size(M, 1)\n",
    "    s = zero(eltype(M))  # a zero hard-typed as the same type as the entry of the matrix\n",
    "    # eltype stands for ELement TYPE - this is now fully generic\n",
    "    for i in 2:n        # Julia uses column-major storage order - faster to traverse any matrix in Julia column-wise\n",
    "        @simd for j in 1:(i-1)    # if I know I'm accessing a contiguous block of memory, I can tell Julia that using @simd\n",
    "            @inbounds s += M[j, i]    # ignore bound checking and just access memory C-style \n",
    "        end\n",
    "    end\n",
    "    s\n",
    "end\n",
    "\n",
    "uppersum(R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at these `@simd` and `@inbouds` annotations: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "@simd\n",
       "\\end{verbatim}\n",
       "Annotate a \\texttt{for} loop to allow the compiler to take extra liberties to allow loop re-ordering\n",
       "\n",
       "\\begin{quote}\n",
       "\\textbf{warning}\n",
       "\n",
       "Warning\n",
       "\n",
       "This feature is experimental and could change or disappear in future versions of Julia. Incorrect use of the \\texttt{@simd} macro may cause unexpected results.\n",
       "\n",
       "\\end{quote}\n",
       "The object iterated over in a \\texttt{@simd for} loop should be a one-dimensional range. By using \\texttt{@simd}, you are asserting several properties of the loop:\n",
       "\n",
       "\\begin{itemize}\n",
       "\\item It is safe to execute iterations in arbitrary or overlapping order, with special consideration for reduction variables.\n",
       "\n",
       "\n",
       "\\item Floating-point operations on reduction variables can be reordered, possibly causing different results than without \\texttt{@simd}.\n",
       "\n",
       "\\end{itemize}\n",
       "In many cases, Julia is able to automatically vectorize inner for loops without the use of \\texttt{@simd}. Using \\texttt{@simd} gives the compiler a little extra leeway to make it possible in more situations. In either case, your inner loop should have the following properties to allow vectorization:\n",
       "\n",
       "\\begin{itemize}\n",
       "\\item The loop must be an innermost loop\n",
       "\n",
       "\n",
       "\\item The loop body must be straight-line code. Therefore, \\href{@ref}{\\texttt{@inbounds}} is   currently needed for all array accesses. The compiler can sometimes turn   short \\texttt{\\&\\&}, \\texttt{||}, and \\texttt{?:} expressions into straight-line code if it is safe   to evaluate all operands unconditionally. Consider using the \\href{@ref}{\\texttt{ifelse}}   function instead of \\texttt{?:} in the loop if it is safe to do so.\n",
       "\n",
       "\n",
       "\\item Accesses must have a stride pattern and cannot be \"gathers\" (random-index   reads) or \"scatters\" (random-index writes).\n",
       "\n",
       "\n",
       "\\item The stride should be unit stride.\n",
       "\n",
       "\\end{itemize}\n",
       "\\begin{quote}\n",
       "\\textbf{note}\n",
       "\n",
       "Note\n",
       "\n",
       "The \\texttt{@simd} does not assert by default that the loop is completely free of loop-carried memory dependencies, which is an assumption that can easily be violated in generic code. If you are writing non-generic code, you can use \\texttt{@simd ivdep for ... end} to also assert that:\n",
       "\n",
       "\\end{quote}\n",
       "\\begin{itemize}\n",
       "\\item There exists no loop-carried memory dependencies\n",
       "\n",
       "\n",
       "\\item No iteration ever waits on a previous iteration to make forward progress.\n",
       "\n",
       "\\end{itemize}\n"
      ],
      "text/markdown": [
       "```\n",
       "@simd\n",
       "```\n",
       "\n",
       "Annotate a `for` loop to allow the compiler to take extra liberties to allow loop re-ordering\n",
       "\n",
       "!!! warning\n",
       "    This feature is experimental and could change or disappear in future versions of Julia. Incorrect use of the `@simd` macro may cause unexpected results.\n",
       "\n",
       "\n",
       "The object iterated over in a `@simd for` loop should be a one-dimensional range. By using `@simd`, you are asserting several properties of the loop:\n",
       "\n",
       "  * It is safe to execute iterations in arbitrary or overlapping order, with special consideration for reduction variables.\n",
       "  * Floating-point operations on reduction variables can be reordered, possibly causing different results than without `@simd`.\n",
       "\n",
       "In many cases, Julia is able to automatically vectorize inner for loops without the use of `@simd`. Using `@simd` gives the compiler a little extra leeway to make it possible in more situations. In either case, your inner loop should have the following properties to allow vectorization:\n",
       "\n",
       "  * The loop must be an innermost loop\n",
       "  * The loop body must be straight-line code. Therefore, [`@inbounds`](@ref) is   currently needed for all array accesses. The compiler can sometimes turn   short `&&`, `||`, and `?:` expressions into straight-line code if it is safe   to evaluate all operands unconditionally. Consider using the [`ifelse`](@ref)   function instead of `?:` in the loop if it is safe to do so.\n",
       "  * Accesses must have a stride pattern and cannot be \"gathers\" (random-index   reads) or \"scatters\" (random-index writes).\n",
       "  * The stride should be unit stride.\n",
       "\n",
       "!!! note\n",
       "    The `@simd` does not assert by default that the loop is completely free of loop-carried memory dependencies, which is an assumption that can easily be violated in generic code. If you are writing non-generic code, you can use `@simd ivdep for ... end` to also assert that:\n",
       "\n",
       "\n",
       "  * There exists no loop-carried memory dependencies\n",
       "  * No iteration ever waits on a previous iteration to make forward progress.\n"
      ],
      "text/plain": [
       "\u001b[36m  @simd\u001b[39m\n",
       "\n",
       "  Annotate a \u001b[36mfor\u001b[39m loop to allow the compiler to take extra liberties to allow\n",
       "  loop re-ordering\n",
       "\n",
       "\u001b[33m\u001b[1m  │ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning\u001b[22m\u001b[39m\n",
       "\u001b[33m\u001b[1m  │\u001b[22m\u001b[39m\n",
       "\u001b[33m\u001b[1m  │\u001b[22m\u001b[39m  This feature is experimental and could change or disappear in\n",
       "\u001b[33m\u001b[1m  │\u001b[22m\u001b[39m  future versions of Julia. Incorrect use of the \u001b[36m@simd\u001b[39m macro may\n",
       "\u001b[33m\u001b[1m  │\u001b[22m\u001b[39m  cause unexpected results.\n",
       "\n",
       "  The object iterated over in a \u001b[36m@simd for\u001b[39m loop should be a one-dimensional\n",
       "  range. By using \u001b[36m@simd\u001b[39m, you are asserting several properties of the loop:\n",
       "\n",
       "    •    It is safe to execute iterations in arbitrary or overlapping\n",
       "        order, with special consideration for reduction variables.\n",
       "\n",
       "    •    Floating-point operations on reduction variables can be reordered,\n",
       "        possibly causing different results than without \u001b[36m@simd\u001b[39m.\n",
       "\n",
       "  In many cases, Julia is able to automatically vectorize inner for loops\n",
       "  without the use of \u001b[36m@simd\u001b[39m. Using \u001b[36m@simd\u001b[39m gives the compiler a little extra\n",
       "  leeway to make it possible in more situations. In either case, your inner\n",
       "  loop should have the following properties to allow vectorization:\n",
       "\n",
       "    •    The loop must be an innermost loop\n",
       "\n",
       "    •    The loop body must be straight-line code. Therefore, \u001b[36m@inbounds\u001b[39m is\n",
       "        currently needed for all array accesses. The compiler can\n",
       "        sometimes turn short \u001b[36m&&\u001b[39m, \u001b[36m||\u001b[39m, and \u001b[36m?:\u001b[39m expressions into straight-line\n",
       "        code if it is safe to evaluate all operands unconditionally.\n",
       "        Consider using the \u001b[36mifelse\u001b[39m function instead of \u001b[36m?:\u001b[39m in the loop if it\n",
       "        is safe to do so.\n",
       "\n",
       "    •    Accesses must have a stride pattern and cannot be \"gathers\"\n",
       "        (random-index reads) or \"scatters\" (random-index writes).\n",
       "\n",
       "    •    The stride should be unit stride.\n",
       "\n",
       "\u001b[36m\u001b[1m  │ \u001b[22m\u001b[39m\u001b[36m\u001b[1mNote\u001b[22m\u001b[39m\n",
       "\u001b[36m\u001b[1m  │\u001b[22m\u001b[39m\n",
       "\u001b[36m\u001b[1m  │\u001b[22m\u001b[39m  The \u001b[36m@simd\u001b[39m does not assert by default that the loop is completely\n",
       "\u001b[36m\u001b[1m  │\u001b[22m\u001b[39m  free of loop-carried memory dependencies, which is an assumption\n",
       "\u001b[36m\u001b[1m  │\u001b[22m\u001b[39m  that can easily be violated in generic code. If you are writing\n",
       "\u001b[36m\u001b[1m  │\u001b[22m\u001b[39m  non-generic code, you can use \u001b[36m@simd ivdep for ... end\u001b[39m to also\n",
       "\u001b[36m\u001b[1m  │\u001b[22m\u001b[39m  assert that:\n",
       "\n",
       "    •    There exists no loop-carried memory dependencies\n",
       "\n",
       "    •    No iteration ever waits on a previous iteration to make forward\n",
       "        progress."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?@simd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "@inbounds(blk)\n",
       "\\end{verbatim}\n",
       "Eliminates array bounds checking within expressions.\n",
       "\n",
       "In the example below the in-range check for referencing element \\texttt{i} of array \\texttt{A} is skipped to improve performance.\n",
       "\n",
       "\\begin{verbatim}\n",
       "function sum(A::AbstractArray)\n",
       "    r = zero(eltype(A))\n",
       "    for i = 1:length(A)\n",
       "        @inbounds r += A[i]\n",
       "    end\n",
       "    return r\n",
       "end\n",
       "\\end{verbatim}\n",
       "\\begin{quote}\n",
       "\\textbf{warning}\n",
       "\n",
       "Warning\n",
       "\n",
       "Using \\texttt{@inbounds} may return incorrect results/crashes/corruption for out-of-bounds indices. The user is responsible for checking it manually. Only use \\texttt{@inbounds} when it is certain from the information locally available that all accesses are in bounds.\n",
       "\n",
       "\\end{quote}\n"
      ],
      "text/markdown": [
       "```\n",
       "@inbounds(blk)\n",
       "```\n",
       "\n",
       "Eliminates array bounds checking within expressions.\n",
       "\n",
       "In the example below the in-range check for referencing element `i` of array `A` is skipped to improve performance.\n",
       "\n",
       "```julia\n",
       "function sum(A::AbstractArray)\n",
       "    r = zero(eltype(A))\n",
       "    for i = 1:length(A)\n",
       "        @inbounds r += A[i]\n",
       "    end\n",
       "    return r\n",
       "end\n",
       "```\n",
       "\n",
       "!!! warning\n",
       "    Using `@inbounds` may return incorrect results/crashes/corruption for out-of-bounds indices. The user is responsible for checking it manually. Only use `@inbounds` when it is certain from the information locally available that all accesses are in bounds.\n",
       "\n"
      ],
      "text/plain": [
       "\u001b[36m  @inbounds(blk)\u001b[39m\n",
       "\n",
       "  Eliminates array bounds checking within expressions.\n",
       "\n",
       "  In the example below the in-range check for referencing element \u001b[36mi\u001b[39m of array \u001b[36mA\u001b[39m\n",
       "  is skipped to improve performance.\n",
       "\n",
       "\u001b[36m  function sum(A::AbstractArray)\u001b[39m\n",
       "\u001b[36m      r = zero(eltype(A))\u001b[39m\n",
       "\u001b[36m      for i = 1:length(A)\u001b[39m\n",
       "\u001b[36m          @inbounds r += A[i]\u001b[39m\n",
       "\u001b[36m      end\u001b[39m\n",
       "\u001b[36m      return r\u001b[39m\n",
       "\u001b[36m  end\u001b[39m\n",
       "\n",
       "\u001b[33m\u001b[1m  │ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning\u001b[22m\u001b[39m\n",
       "\u001b[33m\u001b[1m  │\u001b[22m\u001b[39m\n",
       "\u001b[33m\u001b[1m  │\u001b[22m\u001b[39m  Using \u001b[36m@inbounds\u001b[39m may return incorrect results/crashes/corruption\n",
       "\u001b[33m\u001b[1m  │\u001b[22m\u001b[39m  for out-of-bounds indices. The user is responsible for checking it\n",
       "\u001b[33m\u001b[1m  │\u001b[22m\u001b[39m  manually. Only use \u001b[36m@inbounds\u001b[39m when it is certain from the\n",
       "\u001b[33m\u001b[1m  │\u001b[22m\u001b[39m  information locally available that all accesses are in bounds."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?@inbounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right! Let's time this implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.054047 seconds (5 allocations: 176 bytes)\n"
     ]
    }
   ],
   "source": [
    "@time uppersum(R);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-7802.6497830305125"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function uppersum_boundcheck(M)\n",
    "    n = size(M, 1)\n",
    "    s = zero(eltype(M))  # a zero hard-typed as the same type as the entry of the matrix\n",
    "    # eltype stands for ELement TYPE - this is now fully generic\n",
    "    for i in 2:n        # Julia uses column-major storage order - faster to traverse any matrix in Julia column-wise\n",
    "        @simd for j in 1:(i-1)    # if I know I'm accessing a contiguous block of memory, I can tell Julia that using @simd\n",
    "            s += M[j, i]    # ignore bound checking and just access memory C-style \n",
    "        end\n",
    "    end\n",
    "    s    # this is sufficient for a `return` statement\n",
    "end\n",
    "\n",
    "uppersum(R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what kind of gain we get from losing boundchecking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.115098 seconds (51.16 k allocations: 2.663 MiB)\n"
     ]
    }
   ],
   "source": [
    "@time uppersum_boundcheck(R);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesingly, Julia apparently uses [LLVM](https://llvm.org/) in the background.\n",
    "\n",
    "# Going parallel\n",
    "\n",
    "The idea is: we have a triangle and we want to split it into pieces of equal \"mass\". This is done in the code below, via an instruction that is relatively magical to me right now.\n",
    "\n",
    "For threading to work, note that [as described in the docs](https://docs.julialang.org/en/v1.0/manual/environment-variables/#JULIA_NUM_THREADS-1), you need to set the environment variable `JULIA_NUM_THREADS`. `export JULIA_NUM_THREADS=4` in `.bashrc` worked fine for me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-7802.649783030595"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Base.Threads\n",
    "\n",
    "function upsum_threads(M)\n",
    "    n = size(M, 1)\n",
    "    chunks = nthreads()\n",
    "    sums = zeros(eltype(M), chunks)  # separate subsum for each thread\n",
    "    chunkend = round.(Int, n*sqrt.((1:chunks) ./ chunks))   #split jobs so that each thread has approx. same number of numbers to add\n",
    "    @assert minimum(diff(chunkend)) > 0\n",
    "    chunkstart = [2; chunkend[1:end-1] .+ 1]\n",
    "    @threads for job in 1:chunks     # tell Julia that this part is safe for threading\n",
    "        s = zero(eltype(M))\n",
    "        for i in chunkstart[job]:chunkend[job]\n",
    "            @simd for j in 1:(i-1)\n",
    "                @inbounds s += M[j, i]\n",
    "            end\n",
    "        end\n",
    "        sums[job] = s\n",
    "    end\n",
    "    return sum(sums)\n",
    "end\n",
    "\n",
    "upsum_threads(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.037879 seconds (35 allocations: 2.000 KiB)\n"
     ]
    }
   ],
   "source": [
    "@time upsum_threads(R);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now this is faster than the Numpy. I'm reasonably impressed - but confused as to that one magical line, though. Let's dig into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Int64,1}:\n",
       "  5000\n",
       "  7071\n",
       "  8660\n",
       " 10000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = 4\n",
    "n = 10000\n",
    "round.(Int, n*sqrt.((1:chunks) ./ chunks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huh. Digging deeper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1:4"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1:chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, this is a range..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25:0.25:1.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1:chunks) ./ chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this is where it starts to hit me, as the presenter introduces the `collect` command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Float64,1}:\n",
       " 0.25\n",
       " 0.5 \n",
       " 0.75\n",
       " 1.0 "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect((1:chunks) ./ chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OOOOOOOOOOOOOH. So `./` is a a lazy operator! In other words, if you do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "MethodError",
     "evalue": "MethodError: no method matching sqrt(::StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}})\nClosest candidates are:\n  sqrt(!Matched::Float16) at math.jl:1018\n  sqrt(!Matched::Complex{Float16}) at math.jl:1019\n  sqrt(!Matched::Missing) at math.jl:1070\n  ...",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching sqrt(::StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}})\nClosest candidates are:\n  sqrt(!Matched::Float16) at math.jl:1018\n  sqrt(!Matched::Complex{Float16}) at math.jl:1019\n  sqrt(!Matched::Missing) at math.jl:1070\n  ...",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[43]:1"
     ]
    }
   ],
   "source": [
    "sqrt((1:chunks) ./ chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This errors because you're operating on a `range`, but instead if you do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Float64,1}:\n",
       " 0.5               \n",
       " 0.7071067811865476\n",
       " 0.8660254037844386\n",
       " 1.0               "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqrt.((1:chunks) ./ chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chains of broadcasting operations **\"materialize\" only once** - skipping plenty of unnecessary overhead.\n",
    "\n",
    "This is badass and I have to admit that I'm rather hyped up for Julia now!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  },
  "nikola": {
   "category": "",
   "date": "2019-03-14 11:00:00 UTC+01:00",
   "description": "",
   "link": "",
   "slug": "first-dive-julia",
   "tags": [
    "julia"
   ],
   "title": "First dive into Julia",
   "type": "text"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

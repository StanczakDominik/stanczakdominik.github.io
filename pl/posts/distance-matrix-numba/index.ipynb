{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recently, I've been looking for efficient ways to compute a [distance matrix](https://en.wikipedia.org/wiki/Distance_matrix) in Python. I'm deliberately trying to implement a naive n-body simulation so as to find optimized ways of calculating those, as practice. Let's do that using Numba.\n",
    "\n",
    "<!-- TEASER_END -->\n",
    "\n",
    "As usual, we're going to be using the standard Python scientific stack... and we'll also use Numba, transitioning onto the GPU next week. Let's get those imports prepped:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy, scipy.spatial\n",
    "import numba\n",
    "import sys\n",
    "np.__version__, scipy.__version__, numba.__version__, sys.version\n",
    "from numpy.testing import assert_allclose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get ourselves some sample 3D position data, for twenty thousand particles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.83244056, 0.94442527, 0.57451672],\n",
       "       [0.09049263, 0.08428888, 0.43300003],\n",
       "       [0.29973189, 0.11463598, 0.27817412],\n",
       "       ...,\n",
       "       [0.49628111, 0.1462252 , 0.18381982],\n",
       "       [0.80535628, 0.07900376, 0.19831322],\n",
       "       [0.75236151, 0.02655101, 0.54791037]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = int(1e4)\n",
    "np.random.seed(743)\n",
    "r = np.random.random(size=(N, 3))\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I: CPU distance matrix calculations\n",
    "\n",
    "Let's start out by following up on the [2013 results of Jake Vanderplas](https://jakevdp.github.io/blog/2013/06/15/numba-vs-cython-take-2/):\n",
    "\n",
    "## Direct numpy summation\n",
    "\n",
    "This is the classic approach, but with a major flaw - it allocates a lot of temporary arrays in the meantime, and that takes a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.02 s ± 43.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "def pairwise_numpy(X):\n",
    "    \"\"\"\n",
    "    Reproduced from https://jakevdp.github.io/blog/2013/06/15/numba-vs-cython-take-2/\n",
    "    \"\"\"\n",
    "    return np.sqrt(((X[:, None, :] - X) ** 2).sum(-1))\n",
    "pairwise_numpy_timing = %timeit -o pairwise_numpy(r)\n",
    "pairwise_numpy_result = pairwise_numpy(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's nice to have it for comparison, though.\n",
    "\n",
    "## Direct (slow) Python loop\n",
    "\n",
    "We'll now switch over to doing things Numba-style. This means that we'll use `math` instead of `numpy`, so that the $\\sqrt{x}$ we'll doing is explicitly a scalar operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def scalar_distance(r, output):\n",
    "    N, M = r.shape\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            tmp = 0.0\n",
    "            for k in range(M):\n",
    "                tmp += (r[i, k] - r[j, k])**2\n",
    "            output[i,j] = math.sqrt(tmp)\n",
    "output = np.zeros((N, N), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4min 6s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n",
      "The direct summation implementation is 49.11 slower than NumPy.\n"
     ]
    }
   ],
   "source": [
    "# warning: LONG\n",
    "direct_summation_timeit = %timeit -o -n1 -r1 scalar_distance(r, output)\n",
    "\n",
    "# sanity check!\n",
    "assert_allclose(pairwise_numpy_result, output)\n",
    "\n",
    "print(f\"The direct summation implementation is {direct_summation_timeit.average / pairwise_numpy_timing.average:.2f} slower than NumPy.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, let's simply wrap this in `numba.njit`.\n",
    "\n",
    "Note that the below is equivalent to\n",
    "```python\n",
    "@numba.njit\n",
    "def scalar_distance(...):\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "408 ms ± 16.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "Our Numba implementation is 12.31 times faster than NumPy!\n"
     ]
    }
   ],
   "source": [
    "numba_jit_scalar_distance = numba.njit(scalar_distance)\n",
    "numba_jit_timing = %timeit -o numba_jit_scalar_distance(r, output)\n",
    "\n",
    "assert_allclose(pairwise_numpy_result, output)\n",
    "\n",
    "print(f\"Our Numba implementation is {pairwise_numpy_timing.average/numba_jit_timing.average:.2f} times faster than NumPy!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad! But we can still get speedups by replacing `range` with `numba.prange`, which tells Numba that \"yes, this loop is **trivially** parallelizable\". To do so we use the `parallel=True` flag to `njit`:\n",
    "\n",
    "## Optimal numba solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105 ms ± 5.98 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "Using `parallel=True` grants us a further 3.90x speedup.\n"
     ]
    }
   ],
   "source": [
    "@numba.njit(parallel=True)\n",
    "def numba_jit_scalar_distance_parallel(r, output):\n",
    "    N, M = r.shape\n",
    "    for i in numba.prange(N):\n",
    "        for j in numba.prange(N):\n",
    "            tmp = 0.0\n",
    "            for k in range(M):\n",
    "                tmp += (r[i, k] - r[j, k])**2\n",
    "            output[i,j] = math.sqrt(tmp)\n",
    "\n",
    "numba_jit_parallel_timing = %timeit -o numba_jit_scalar_distance_parallel(r, output)\n",
    "\n",
    "assert_allclose(pairwise_numpy_result, output)\n",
    "\n",
    "print(f\"Using `parallel=True` grants us a further {numba_jit_timing.average/numba_jit_parallel_timing.average:.2f}x speedup.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that I've got four cores on this laptop, so this problem is truly trivially parallelilzable. This is nice because `numba.prange` is actually a no-op when not using it from within `numba`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4min 2s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n",
      "242.71444s vs 246.70353s.\n"
     ]
    }
   ],
   "source": [
    "def scalar_distance_prange(r, output):\n",
    "    N, M = r.shape\n",
    "    for i in numba.prange(N):\n",
    "        for j in numba.prange(N):\n",
    "            tmp = 0.0\n",
    "            for k in range(M):\n",
    "                tmp += (r[i, k] - r[j, k])**2\n",
    "            output[i,j] = math.sqrt(tmp)\n",
    "\n",
    "direct_summation_prange_timeit = %timeit -o -n1 -r1 scalar_distance_prange(r, output)\n",
    "assert_allclose(pairwise_numpy_result, output)\n",
    "print(f\"{direct_summation_prange_timeit.average:.5f}s vs {direct_summation_timeit.average:.5f}s.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's something you can just throw in \"for free\", lets you debug stuff just as easily, and once you end up turning on `parallel = True`, it lets speed ups kick in.\n",
    "\n",
    "However, suppose we wanted to have this run *really* fast. What we then could do is turn to the GPU. And this is exactly what we'll be doing next week!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cupy]",
   "language": "python",
   "name": "conda-env-cupy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nikola": {
   "category": "",
   "date": "2019-07-25 08:00:00 UTC+02:00",
   "description": "",
   "link": "",
   "slug": "distance-matrix-numba",
   "tags": [
    "numba",
    "simulation",
    "nbody",
    "python"
   ],
   "title": "Better Numba calculation of inter-particle distance matrices",
   "type": "text"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

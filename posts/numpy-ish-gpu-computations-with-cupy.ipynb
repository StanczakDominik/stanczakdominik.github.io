{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've recently come across the amazing [CuPy](https://github.com/cupy/cupy) library, and given that I haven't updated this blog in a while, I figured this would be a great opportunity to showcase a few of its capabilities.\n",
    "\n",
    "If you haven't heard yet, **CuPy is NumPy, but on the GPU**, and it's amazing how close that simple description is to reality.\n",
    "\n",
    "First things first! Make sure you've [installed it (I used Conda with Python 3.6)](https://docs-cupy.chainer.org/en/latest/install.html) and that your Nvidia drivers are on. On my laptop, running an integrated Intel and dedicated Nvidia GPU, I had to simply run `sudo modprobe nvidia`.  Let's see if that worked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jan 22 08:08:35 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 415.27       Driver Version: 415.27       CUDA Version: 10.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 106...  Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   65C    P0    24W /  N/A |      0MiB /  6078MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yup! Let's get to it. We'll compare it with NumPy, of course:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm mostly interested in operations on dense matrices, so let's get ourselves a sample one. I'm not using an insanely large array due to `MemoryError`s, but `2**20` floats should be a reasonable benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.10388936, 0.27674225, 0.09349157, ..., 0.59858586, 0.01545899,\n",
       "        0.20201765],\n",
       "       [0.81588711, 0.19722361, 0.66885061, ..., 0.83687175, 0.15600763,\n",
       "        0.6171922 ],\n",
       "       [0.73374963, 0.66466975, 0.55082473, ..., 0.68605053, 0.93384799,\n",
       "        0.84729118],\n",
       "       ...,\n",
       "       [0.76718438, 0.40130284, 0.81041205, ..., 0.42829758, 0.42465592,\n",
       "        0.67533214],\n",
       "       [0.11546777, 0.35548417, 0.645703  , ..., 0.24879487, 0.58897384,\n",
       "        0.98993676],\n",
       "       [0.96847189, 0.21391942, 0.70259718, ..., 0.32546387, 0.97123257,\n",
       "        0.99439515]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 1024\n",
    "A = np.random.random((N, N))\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CuPy API is basically Numpy's API, with a few minor differences here and there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5967192 , 0.51631595, 0.49980612, ..., 0.52830527, 0.4521689 ,\n",
       "        0.27857874],\n",
       "       [0.80999042, 0.32971922, 0.74034167, ..., 0.7316576 , 0.05339145,\n",
       "        0.67494372],\n",
       "       [0.66954774, 0.08282191, 0.06237442, ..., 0.85821394, 0.33912042,\n",
       "        0.00146102],\n",
       "       ...,\n",
       "       [0.87827673, 0.58662314, 0.97428079, ..., 0.1239315 , 0.90813556,\n",
       "        0.55808706],\n",
       "       [0.59890383, 0.54480358, 0.59180028, ..., 0.03094922, 0.54241454,\n",
       "        0.45274242],\n",
       "       [0.34639887, 0.49254118, 0.28915567, ..., 0.86708966, 0.97695957,\n",
       "        0.63873008]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = cp.random.random((N, N))\n",
    "B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing that can be noticed already - that displayed numbers! Right there, in Jupyter! All the memory transfer is done for you as need be, though you can also force it as needed. To me, that's pretty amazing! Let's make sure this is actually on the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jan 22 08:08:36 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 415.27       Driver Version: 415.27       CUDA Version: 10.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 106...  Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   66C    P2    24W /  N/A |     95MiB /  6078MiB |      1%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0     12081      C   ...ik/.miniconda3/envs/nbody3.6/bin/python    85MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly a bunch of memory is allocated.\n",
    "\n",
    "## A few benchmarks\n",
    "\n",
    "All right, let's get to the actual number crunching. Let's take the simple element-wise log of each element in the array (on CPU that's going to run with the MKL-accelerated Numpy on an i7):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.4 ms ± 1.53 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<TimeitResult : 24.4 ms ± 1.53 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%timeit -o\n",
    "np.log(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Respectable, I suppose. Let's see how CuPy fares against that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453 µs ± 735 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<TimeitResult : 453 µs ± 735 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%timeit -o\n",
    "cp.log(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantly, I noticed two things:\n",
    "\n",
    "1. My laptop fan started spinning up immediately after running that command. Clearly something more intense is going on there.\n",
    "2. My screen went black. Fun fact: I wrote this post out of bed, without having plugged my laptop in - and my current system configuration did not enjoy having a power-hungry GPU try to run on battery, so it just switched off instantly. Consider yourself warned!\n",
    "\n",
    "After rebooting and using the classic `Restart and run all`, a third fun fact occured to me: a different SI prefix on the GPU result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53.877025466882685"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "__.average / _.average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a pretty okay speedup for swapping `n` to `c` in the import statement. \n",
    "\n",
    "Let's see how well it's going to parallelize a matrix multiplication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.2 ms ± 3.19 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "cpu_operator = %timeit -o A @ A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.7 ms ± 48.6 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "gpu_operator = %timeit -o B @ B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how that's literally the same operation in terms of code, as we're not using Numpy's functions, rather - both of these classes define an `@` operator. This is going to come up later..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3472357440051654"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_operator.average / gpu_operator.average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, suprisingly, this is nowhere near as large of a speedup as I would expect! My results seem to vary a bit, though:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.7 ms ± 4.83 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "gpu_operator_saved = %timeit -o B2 = B @ B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.37 ms ± 10.8 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "gpu_dot = %timeit -o cp.dot(B, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.4 ms ± 3.26 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "gpu_dot_saved = %timeit -o B3 = cp.dot(B, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.7 ms ± 9.19 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "Btarget= cp.empty_like(B)\n",
    "gpu_dot_out = %timeit -o cp.dot(B, B, Btarget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think I may come back to the matrix multiplication issue in the future, because it seems like there are multiple ways to do it and it's not clear which one is the best. Weirdly, the winner seems to be `.dot(B, B)`, but...without saving. Let's keep this post to an overview of CuPy's functionality and possibly revisit that in the future. This may have been a BLAS/cuBLAS issue that I don't quite understand yet.\n",
    "\n",
    "## Further functionality review\n",
    "\n",
    "Okay, but what actually is `B`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cupy.core.core.ndarray"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All right, some internal Cupy `ndarray` class. It's pretty simple to turn it into something in host device memory, though:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cp.asnumpy(B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.5967192 , 0.51631595, 0.49980612, ..., 0.52830527, 0.4521689 ,\n",
       "        0.27857874]),\n",
       " array([0.5967192 , 0.51631595, 0.49980612, ..., 0.52830527, 0.4521689 ,\n",
       "        0.27857874]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B[0], cp.asnumpy(B)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to make sure this is actually the same array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "object __array__ method not producing an array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-8ff31bdd3597>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36mallclose\u001b[0;34m(a, b, rtol, atol, equal_nan)\u001b[0m\n\u001b[1;32m   2268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2269\u001b[0m     \"\"\"\n\u001b[0;32m-> 2270\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0matol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mequal_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mequal_nan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2271\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36misclose\u001b[0;34m(a, b, rtol, atol, equal_nan)\u001b[0m\n\u001b[1;32m   2352\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mless_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrtol\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2354\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2355\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masanyarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     \"\"\"\n\u001b[0;32m--> 553\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: object __array__ method not producing an array"
     ]
    }
   ],
   "source": [
    "np.allclose(B, cp.asnumpy(B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Close, but no cigar! I think this may be getting out of date relatively soon, but right now NumPy doesn't know how to handle our `B` GPU array. Another example of this is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "object __array__ method not producing an array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-31256e41f3b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: object __array__ method not producing an array"
     ]
    }
   ],
   "source": [
    "np.log(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What you could do instead is compare this right on the GPU, going from GPU to host to GPU again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cupy' has no attribute 'allclose'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-159d67e41f21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'cupy' has no attribute 'allclose'"
     ]
    }
   ],
   "source": [
    "cp.allclose(B, cp.asarray(cp.asnumpy(B)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this is, actually, the first time I saw cupy **not** implementing something in NumPy's API! It's pretty easy to get around this, in this instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp.all(cp.isclose(B, cp.asarray(cp.asnumpy(B))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I guess that's no *proof* that this works correctly, but it's at least an argument :)\n",
    "\n",
    "However... Wait a minute. What's that `array` thing doing there? As far as I have been able to figure out, this is a single element array allocated in GPU memory that `.all()` reduces our boolean *NxN* `isclose` array to. It's pretty simple to convert to a normal Python bool, though:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool(_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape works, as does summing along an axis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[504.85090841],\n",
       "       [524.895922  ],\n",
       "       [511.81485662],\n",
       "       ...,\n",
       "       [505.07597442],\n",
       "       [505.44331639],\n",
       "       [508.71877327]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B.reshape(N, N, 1).sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So do statistical functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.49501721, 0.51289292, 0.51160649, ..., 0.49777249, 0.50287185,\n",
       "       0.49873693])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can raise stuff to powers and sum to scalars:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(262231.4456098349, array(262330.20455528))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(A**3).sum(), (B**3).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And of course, once again we need to force a cast to a Python float:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262330.2045552799"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(_[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also, if you want to, sum into previously allocated arrays (I was thinking of using this to test performance differences between `cupy` and `numba.cuda`, haven't gotten to that yet, though):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 9.77517107e-04, 1.95503421e-03, ...,\n",
       "       9.98044966e-01, 9.99022483e-01, 1.00000000e+00])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ax = np.linspace(0, 1, N)\n",
    "Ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1024, 1024), (1024,))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape, Ax.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([497.48857494, 510.25752741, 493.57497492, ..., 515.3009242 ,\n",
       "       499.92205554, 512.74308963])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.sum(axis=1, out=Ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 9.77517107e-04, 1.95503421e-03, ...,\n",
       "       9.98044966e-01, 9.99022483e-01, 1.00000000e+00])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bx = cp.linspace(0, 1, N)\n",
    "Bx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1024, 1024), (1024,))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B.shape, Bx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([504.85090841, 524.895922  , 511.81485662, ..., 505.07597442,\n",
       "       505.44331639, 508.71877327])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B.sum(axis=1, out=Bx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([504.85090841, 524.895922  , 511.81485662, ..., 505.07597442,\n",
       "       505.44331639, 508.71877327])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random numbers start from different seeds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.01273565)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp.random.seed(0)\n",
    "Rgpu = cp.random.random()\n",
    "np.random.seed(0)\n",
    "Rcpu = np.random.random()\n",
    "Rgpu - Rcpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp.random.seed(0)\n",
    "Rgpu2 = cp.random.random()\n",
    "Rgpu2 - Rgpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexing works just like we know and love it from numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([504.85090841, 524.895922  , 511.81485662, ..., 505.07597442,\n",
       "       505.44331639, 508.71877327])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3.        , 524.895922  , 511.81485662, ..., 505.07597442,\n",
       "       505.44331639, 508.71877327])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bx[0] = 3\n",
    "Bx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3.        ,  -1.        , 511.81485662, ...,  -1.        ,\n",
       "       505.44331639,  -1.        ])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bx[1::2] = -1\n",
    "Bx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The amazing power tool that is `einsum` works as well, let's use it to compute the array's trace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(493.15631992), array(493.15631992))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp.einsum('ii->', B), cp.sum(cp.diag(B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing CPU and GPU agnostic code\n",
    "This is a concept I found in CuPy's library and absolutely fell in love.\n",
    "\n",
    "In some cases, you can use array methods and operators to do what you need. This is where that `A @ A` and `B @ B` concept comes back. However, that's not always possible. For example, there isn't a `.log()` method.\n",
    "\n",
    "HOWEVER, the CuPy folks had a pretty ingenious idea for solving that! Just watch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-2.26442884, -1.28466872, -2.36988397, ..., -0.51318531,\n",
       "         -4.16956465, -1.59940023],\n",
       "        [-0.20347928, -1.62341712, -0.40219454, ..., -0.17808444,\n",
       "         -1.85785034, -0.4825748 ],\n",
       "        [-0.30958741, -0.40846499, -0.59633861, ..., -0.37680399,\n",
       "         -0.0684416 , -0.16571087],\n",
       "        ...,\n",
       "        [-0.26502811, -0.91303893, -0.21021246, ..., -0.84793704,\n",
       "         -0.85647603, -0.39255065],\n",
       "        [-2.15876381, -1.03427455, -0.43741564, ..., -1.39112655,\n",
       "         -0.52937351, -0.01011422],\n",
       "        [-0.03203582, -1.54215589, -0.35297155, ..., -1.12250382,\n",
       "         -0.02918932, -0.00562062]]),\n",
       " array([[-0.51630862, -0.66103639, -0.69353501, ..., -0.638081  ,\n",
       "         -0.79369951, -1.27805454],\n",
       "        [-0.21073286, -1.10951384, -0.30064348, ..., -0.31244264,\n",
       "         -2.93010466, -0.39312597],\n",
       "        [-0.40115281, -2.4910626 , -2.7746    , ..., -0.15290186,\n",
       "         -1.08140002, -6.52862238],\n",
       "        ...,\n",
       "        [-0.12979355, -0.53337268, -0.02605573, ..., -2.08802627,\n",
       "         -0.09636162, -0.5832403 ],\n",
       "        [-0.51265425, -0.60732996, -0.52458607, ..., -3.47540747,\n",
       "         -0.61172474, -0.79243193],\n",
       "        [-1.06016435, -0.70817722, -1.24079009, ..., -0.1426129 ,\n",
       "         -0.02331001, -0.44827332]]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def agnostic_log(array):\n",
    "    xp = cp.get_array_module(array)\n",
    "    return xp.log(array)\n",
    "\n",
    "agnostic_log(A), agnostic_log(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same function handles two completely different array types!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<module 'numpy' from '/home/dominik/.local/lib/python3.6/site-packages/numpy/__init__.py'>,\n",
       " <module 'cupy' from '/home/dominik/.miniconda3/envs/nbody3.6/lib/python3.6/site-packages/cupy/__init__.py'>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp.get_array_module(A), cp.get_array_module(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is so simple, I absolutely love it. It's not perfect (you still have to define a new function), but it's a nice workaround. [It may not be necessary for a lot longer, too...](https://github.com/numpy/numpy/blob/master/doc/release/1.16.0-notes.rst#numpy-functions-now-support-overrides-with-__array_function__)\n",
    "\n",
    "And given that I'm ending on links, I'll just add [Matthew Rocklin's post about prototype GPU arrays on Dask clusters](http://matthewrocklin.com/blog/work/2019/01/03/dask-array-gpus-first-steps).\n",
    "\n",
    "To sum up: CuPy is awesome, if you've got a GPU lying around (for games, etc), you can very easily use it for your number crunching as well!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nbody3.6]",
   "language": "python",
   "name": "conda-env-nbody3.6-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
   },
  "nikola": {
      "category": "",
      "date": "2019-01-22 08:25:28 UTC+01:00",
      "description": "",
      "link": "",
      "slug": "numpy-ish-gpu-computations-with-cupy",
      "tags": "cupy",
      "title": "NumPy-ish GPU computations with CuPy",
      "type": "text"
       }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
